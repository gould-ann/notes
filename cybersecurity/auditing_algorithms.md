# Auditing Algorithms

- Palantir and NYPD

- algorithms being used for different assessments in the piblic setting

- transparency is not enough in terms of evaluation

- using algorithms to evaluate others but not quite knowing the meaning behind those assessments 

- Human element of algorithms... Potentially retraining government agencies about the "precautions" almost of algorithms 

- one input "part of the issue is to stop training algorithms"

- hard to find an algorithm that is true and not biased 
	- but also looking into other scenarios... like the court system. What is biased and what is not?
	- what if the data is skcewed?
- very... difficult... Hard to satisfy everyone under one circumstance

- enchanced due process with algorithms

- try not to make AI a "checkbox" when working 
- 
- people don't know how these decisions are being made